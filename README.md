# AI Chat (Geany Plugin)

> Local AI chat inside Geany â€” streaming responses, send editor selection, stop, pretty code blocks (GtkSourceView), copy/insert into editor.

**Author:** GPT-5 Thinking (ChatGPT)  
**License:** MIT

**Languages:** [English](#english) Â· [FranÃ§ais](#franÃ§ais)

---

## English

### âœ¨ Features
- Chat pane in Geanyâ€™s Message Window (bottom panel)
- **Streaming** replies (Ollama JSON-lines / OpenAI-compatible SSE)
- **Send editor selection** as prompt
- **Stop** ongoing generation
- Markdown **```fences```** with **syntax highlighting** (GtkSourceView)
- Per-block **Copy** and **Insert into editor**
- **Auto-scroll** during streaming
- Basic on-disk **preferences** (URL, model, temperature, streaming, API key)

> Coming next: **clickable links** and **blockquote** styling.

---

### ğŸ“¦ Dependencies (Debian/Ubuntu)
```bash
sudo apt update
sudo apt install -y   build-essential pkg-config   libgtk-3-dev libcurl4-openssl-dev   libgeany-dev libgtksourceview-3.0-dev
# Optional runtime:
#   ollama  (for local models)
```
> If your distro ships GtkSourceView 4, use `libgtksourceview-4-dev` and replace `gtksourceview-3.0` with `gtksourceview-4` in the Makefile.

---

### ğŸ› ï¸ Build & Install
```bash
make
make install   # installs ai_chat.so to ~/.config/geany/plugins/
```
System-wide (path may vary by distro):
```bash
sudo mkdir -p /usr/lib/x86_64-linux-gnu/geany
sudo cp ai_chat.so /usr/lib/x86_64-linux-gnu/geany/
# or sometimes:
# sudo cp ai_chat.so /usr/lib/geany/
```

---

### ğŸš€ Use
1. Open Geany â†’ **Tools â†’ Plugin Manager** â†’ enable **AI Chat (pro)**.  
2. Open the **Chat IA** tab in the bottom panel.  
3. Configure:
   - **Backend:** *Ollama* or *OpenAI-compatible*
   - **Base URL:** e.g. `http://127.0.0.1:11434` (Ollama) or your API host
   - **Model:** e.g. `llama3:8b` (Ollama), or a remote model name
   - **Temperature, Streaming, API Key** (if needed)  
4. Type your message and press **Enter** to send (**Shift+Enter** for newline).
5. Use **Send selection** to send the current editor selection.
6. In replies:
   - Code blocks have **Copy** & **Insert into editor** buttons.
7. **Stop** cancels the current request, **Reset history** clears memory.

---

### âš™ï¸ Configuration
A config file is stored at:
```
~/.config/geany/ai_chat.conf
```
It keeps: backend, base URL, model, temperature, streaming flag, API key.

---

### ğŸ©º Troubleshooting
- **Plugin doesnâ€™t show up**
  - Verify `ai_chat.so` is in `~/.config/geany/plugins/` (or the system plugin dir).
  - Make sure `libgeany-dev` and Geany (GTK3) are installed for your version.
- **â€œrequires executable stackâ€ linker warning**
  - The build uses hardening flags (`-Wl,-z,noexecstack -Wl,-z,relro -Wl,-z,now`).
- **Clicks in the chat try to open a file in Geany**
  - The chat UI swallows those events; if you still see â€œFile not foundâ€, ensure youâ€™re on the latest build.
- **Weird escape sequences in replies (e.g., `\u003e`, `\"`)**
  - Handled: JSON strings are fully un-escaped in the stream.
- **HTTP errors**
  - Check Base URL / model name. For OpenAI-compatible endpoints, set your **API key**.

---

### ğŸ” Notes
- Requests are sent to your configured endpoint (local Ollama or remote API).
- No telemetry, no background network activity beyond your explicit prompts.

---

### ğŸ—ºï¸ Roadmap
- Clickable links in messages  
- Visual blockquotes (`>`)  
- Optional light/dark theming toggle  
- Heuristic language detection for code fences without a `lang` hint

---

### ğŸ¤ Contributing
PRs welcome! Please include:
- OS/distro, Geany version, GtkSourceView version (3 or 4)
- Steps to reproduce issues
- Minimal patches (keep GTK main-loop thread safety via `g_idle_add`)

---

### ğŸ“œ License
MIT â€” see `LICENSE`.

---

## FranÃ§ais

### âœ¨ FonctionnalitÃ©s
- Onglet de chat dans la **fenÃªtre de messages** de Geany (panneau bas)
- RÃ©ponses en **streaming** (JSON-lines Ollama / SSE OpenAI-compatible)
- **Envoyer la sÃ©lection** de lâ€™Ã©diteur comme prompt
- **Stop** pour annuler la gÃ©nÃ©ration
- **Blocs ```code```** avec **coloration syntaxique** (GtkSourceView)
- Boutons par bloc : **Copier** & **InsÃ©rer dans lâ€™Ã©diteur**
- **Auto-scroll** pendant le stream
- **PrÃ©fÃ©rences** sur disque (URL, modÃ¨le, tempÃ©rature, streaming, clÃ©)

> Ã€ venir : **liens cliquables** et **blockquote** stylÃ©s.

---

### ğŸ“¦ DÃ©pendances (Debian/Ubuntu)
```bash
sudo apt update
sudo apt install -y   build-essential pkg-config   libgtk-3-dev libcurl4-openssl-dev   libgeany-dev libgtksourceview-3.0-dev
# Optionnel Ã  lâ€™exÃ©cution :
#   ollama  (pour modÃ¨les locaux)
```
> Si votre distribution fournit GtkSourceView 4, utilisez `libgtksourceview-4-dev` et remplacez `gtksourceview-3.0` par `gtksourceview-4` dans le Makefile.

---

### ğŸ› ï¸ Compilation & Installation
```bash
make
make install   # installe ai_chat.so dans ~/.config/geany/plugins/
```
Installation systÃ¨me (le chemin peut varier) :
```bash
sudo mkdir -p /usr/lib/x86_64-linux-gnu/geany
sudo cp ai_chat.so /usr/lib/x86_64-linux-gnu/geany/
# ou parfois :
# sudo cp ai_chat.so /usr/lib/geany/
```

---

### ğŸš€ Utilisation
1. Ouvrir Geany â†’ **Outils â†’ Gestionnaire de plugins** â†’ activer **AI Chat (pro)**.  
2. Ouvrir lâ€™onglet **Chat IA** (panneau du bas).  
3. ParamÃ©trer :
   - **Backend** : *Ollama* ou *OpenAI-compatible*
   - **URL** : ex. `http://127.0.0.1:11434` (Ollama) ou votre API
   - **ModÃ¨le** : ex. `llama3:8b` (Ollama), ou un modÃ¨le distant
   - **TempÃ©rature, Streaming, ClÃ© API** (si besoin)  
4. Saisir le message, **EntrÃ©e** pour envoyer (**Shift+EntrÃ©e** pour retour Ã  la ligne).
5. **Envoyer sÃ©lection** pour envoyer la sÃ©lection de lâ€™Ã©diteur.
6. Dans les rÃ©ponses :
   - Les blocs de code ont **Copier** & **InsÃ©rer dans lâ€™Ã©diteur**.
7. **Stop** annule la requÃªte en cours, **RÃ©init. histo** vide lâ€™historique.

---

### âš™ï¸ Configuration
Fichier :
```
~/.config/geany/ai_chat.conf
```
Contient : backend, URL, modÃ¨le, tempÃ©rature, streaming, clÃ© API.

---

### ğŸ©º DÃ©pannage
- **Le plugin nâ€™apparaÃ®t pas**
  - VÃ©rifiez `~/.config/geany/plugins/ai_chat.so` (ou le rÃ©pertoire systÃ¨me).
  - Assurez-vous que `libgeany-dev` et Geany (GTK3) sont installÃ©s pour votre version.
- **Avertissement â€œexecutable stackâ€**
  - Le link inclut `-Wl,-z,noexecstack -Wl,-z,relro -Wl,-z,now`.
- **Cliquer dans le chat ouvre â€œFichier non trouvÃ©â€**
  - Les clics sont neutralisÃ©s dans notre onglet ; mettez Ã  jour si besoin.
- **SÃ©quences dâ€™Ã©chappement visibles (`\u003e`, `\"`)**
  - GÃ©rÃ© : les chaÃ®nes JSON sont dÃ©s-Ã©chappÃ©es pendant le stream.
- **Erreurs HTTP**
  - VÃ©rifiez lâ€™URL / le nom de modÃ¨le. Pour lâ€™API OpenAI-compatible, dÃ©finissez votre **clÃ©**.

---

### ğŸ” Notes
- Les requÃªtes partent vers lâ€™endpoint configurÃ© (Ollama local ou API distante).
- Aucune tÃ©lÃ©mÃ©trie, pas dâ€™activitÃ© rÃ©seau hors envoi explicite.

---

### ğŸ—ºï¸ Feuille de route
- Liens cliquables dans les messages  
- Blockquotes (`>`) avec style  
- Bascule clair/sombre  
- DÃ©tection heuristique du langage quand la fence nâ€™indique pas `lang`

---

### ğŸ¤ Contribuer
PRs bienvenues ! Merci dâ€™indiquer :
- OS/distro, version de Geany, version GtkSourceView (3 ou 4)
- Ã‰tapes de reproduction
- Patches minimalistes (respect des mises Ã  jour UI via `g_idle_add`)

---

### ğŸ“œ Licence
MIT â€” voir `LICENSE`.
